# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13nisyrAWlbRAkvWpfONKLHbjKlhiZ3BS
"""

from google.colab import drive
drive.mount('/content/drive')

import glob
from skimage.io import imread
import numpy as np
import pandas as pd

#! pip install tensorflow-gpu==1.10.0

from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

class dataframe():
    def __init__(self):
        self.Path='/content/drive/MyDrive/teeth/crop_rotated_1-5/*.png'
        self.csv_path='/content/drive/MyDrive/teeth/train/nor_img_2020.csv'
        self.image=[]
        self.Label = []
        self.Label2=[]
        self.comb=[]
    def crop_image(self):
        img_path=sorted(glob.glob(self.Path))
        for i in range(len(img_path)):
            a = imread(img_path[i])
            m,n=a.shape
            b=np.zeros((m,n,3))
            for j in range(0,3):
                b[:,:,j]=a
            self.image.append(b)
        return self.image
    def lab(self):
        ori1 = pd.read_csv(self.csv_path) 
        title =list(ori1.columns[:])
        
        for i in range(len(ori1[title[2]])):
            for j in range(0,6):
                if ori1[title[0]][i]==0:
                    print(ori1[title[2]][i]+"_T1")
                else:
                    self.Label.append(ori1[title[0]][i])
            for j in range(0,6):
                if ori1[title[1]][i]==0:
                    print(ori1[title[2]][i]+"_T2")
                else:
                    self.Label.append(ori1[title[1]][i])
        return self.Label
    def lab2(self):
        for j in range(len(self.Label)):
            if self.Label[j] ==1:
                self.Label2.append([1,0,0,0,0])
            if self.Label[j] ==2:
                self.Label2.append([0,1,0,0,0])
            if self.Label[j] ==3:
                self.Label2.append([0,0,1,0,0])
            if self.Label[j] ==4:
                self.Label2.append([0,0,0,1,0])
            if self.Label[j] ==5:
                self.Label2.append([0,0,0,0,1])
        return self.Label2
    def combine(self):
        
        for i in range(len(self.image)):
            two=[self.image[i],self.Label2[i]]
            self.comb.append(two)
        return self.comb

if __name__ == '__main__':
    Data=dataframe()
    Data.crop_image()
    Data.lab()
    Data.lab2()
    Data.combine()

from sklearn.model_selection import train_test_split
import random
from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping , CSVLogger 
from tensorflow.keras.optimizers import Adam,SGD

train_data, vali_data = train_test_split(Data.comb,random_state=0,shuffle=True,train_size=0.7)

def data_gan_fn(  data, batch_size  ):
    data = random.sample( data , len(data) )
    j = 0
    img_set1=[]
    Lab=[]
    while True:
        batch_start = j*batch_size
        if ( batch_start + batch_size ) > len( data ):
            img_set1=[]
            Lab=[]
            batch_start2 = 0
            batch_end = len( data )
            batch_end2 = batch_start + batch_size - len( data )
            out_set = data[ batch_start : batch_end ] + data[ batch_start2 : batch_end2 ]
            for i in range(len(out_set)):
                img_set1.append(out_set[i][0])
                Lab.append(out_set[i][1])
            img_set1=np.stack(img_set1)
            Lab=np.stack(Lab)
            yield img_set1,Lab
        else :
            img_set1=[]
            Lab=[]
            out_set = data[ batch_start : batch_start + batch_size ]
            for i in range(len(out_set)):
                img_set1.append(out_set[i][0])
                Lab.append(out_set[i][1])
            img_set1=np.stack(img_set1)
            Lab=np.stack(Lab)
            yield img_set1,Lab
        j = j + 1
        if (  j*batch_size )  >=  len( data ):
            j = 0
            img_set1=[]
            Lab=[]

from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,Flatten
from tensorflow.keras.models import Model

model = VGG16(weights='imagenet', include_top=True) 
model.summary()

model.layers.pop()
x = model.layers[-1].output
x=Dense(5, activation='relu')(x)
x=Dense(5, activation='softmax')(x)
# 重新建立模型結構
model=Model(model.input,x)
model.summary()

model.compile( optimizer = Adam( lr = 1e-6 ) , 
              loss = 'categorical_crossentropy' , 
              metrics=['accuracy'] )
epoch = 50000000
batch_size = 2
data_gen  = data_gan_fn(train_data ,batch_size )
val_data = data_gan_fn(vali_data ,batch_size )
steps_per_epoch = int( np.ceil( len( train_data )/batch_size ) )
validation_steps = int( np.ceil( len(vali_data )/batch_size ) )
model_path =   '/content/drive/MyDrive/teeth/saved_models/NTP.h5' 
check_point = ModelCheckpoint( model_path,monitor='val_loss' , 
                              save_best_only= True , verbose = 1)
csv_logger = CSVLogger( '/content/drive/MyDrive/teeth/logs/NTP.log '  )
#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, 
#                   patience=40, min_delta=0.0001)
result = model.fit_generator( data_gen , epochs=epoch , verbose=True , 
                              steps_per_epoch=steps_per_epoch  , 
                              callbacks=[ check_point , csv_logger] , 
                              validation_data = val_data,
                              validation_steps = validation_steps)
